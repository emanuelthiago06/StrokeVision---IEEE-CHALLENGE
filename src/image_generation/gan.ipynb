{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.api as keras\n",
    "from keras.api import layers\n",
    "from keras.api.layers import Conv2D, LeakyReLU, Flatten, Dropout, Dense, Softmax, BatchNormalization, UpSampling2D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (128, 128)\n",
    "channel = 1\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 32\n",
    "latent_dim_size = 128\n",
    "dataset_path = \"../../data/train/\"\n",
    "complete_hist = {\n",
    "    'loss_dis': [],\n",
    "    'loss_gen': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class miniBatch(keras.layers.Layer):\n",
    "    def __init__(self,num_kernels,kernel_dim):\n",
    "        super(miniBatch,self).__init__()\n",
    "        self.num_kernels = num_kernels\n",
    "        self.kernel_dim = kernel_dim\n",
    "        #self.batch_size = batch_size\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        print(input_shape)\n",
    "        self.T = self.add_weight(\n",
    "            shape=(input_shape[-1],self.num_kernels*self.kernel_dim), # Teoricamente 128x500\n",
    "            initializer='random_normal',\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        M = tf.matmul(x,self.T) # teoricamente 128x128 \\times 128x500 = 128x500\n",
    "        M = tf.reshape(M,(-1,self.num_kernels,self.kernel_dim)) # teoricamente 128x100x5\n",
    "        M_T = tf.expand_dims(M,1) # teoricamente 128x1x100x5\n",
    "        M = tf.expand_dims(M,0) # teoricamente 1x128x100x5\n",
    "        diff = tf.abs(M-M_T)\n",
    "        exp_diff = tf.exp(-tf.reduce_mean(diff,-1))\n",
    "        miniBatch_features = tf.reduce_sum(exp_diff,1)\n",
    "        output = tf.concat([x,miniBatch_features],-1)\n",
    "        return output\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # Define a forma de saída explicitamente\n",
    "        return (input_shape[0], input_shape[1] + self.num_kernels)\n",
    "    \n",
    "class SelfAttention(keras.layers.Layer):\n",
    "    def __init__(self, filters):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.filters = filters\n",
    "        self.query_conv = Conv2D(filters // 8, kernel_size=1)\n",
    "        self.key_conv = Conv2D(filters // 8, kernel_size=1)\n",
    "        self.value_conv = Conv2D(filters, kernel_size=1)\n",
    "        self.softmax = Softmax(axis=-1)\n",
    "    \n",
    "    def call(self, x):\n",
    "        batch, height, width, channels = tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[2], tf.shape(x)[3]\n",
    "\n",
    "        Q = tf.reshape(self.query_conv(x), (batch, height * width, -1))  # [B, HW, C/8]\n",
    "        K = tf.reshape(self.key_conv(x), (batch, -1, height * width))    # [B, C/8, HW]\n",
    "        V = tf.reshape(self.value_conv(x), (batch, height * width, -1))  # [B, HW, C]\n",
    "\n",
    "        attention_map = self.softmax(tf.matmul(Q, K))  # [B, HW, HW]\n",
    "\n",
    "        attention_output = tf.matmul(attention_map, V)  # [B, HW, C]\n",
    "        attention_output = tf.reshape(attention_output, (batch, height, width, channels))\n",
    "\n",
    "        return attention_output + x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "def loss_discriminador(real_output, fake_output):\n",
    "    real_loss = keras.losses.BinaryCrossentropy()(tf.ones_like(real_output)*tf.random.uniform((1,),.89,.99), real_output)\n",
    "    fake_loss = keras.losses.BinaryCrossentropy()(tf.zeros_like(fake_output), fake_output)\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "def loss_gerador(fake_output):\n",
    "    return keras.losses.BinaryCrossentropy()(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "\n",
    "\n",
    "def create_generator():\n",
    "\n",
    "    input = layers.Input((latent_dim_size,))\n",
    "    x = layers.Dense(4*4*1024)(input)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.Reshape((4, 4, x.shape[-1]//4//4))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "\n",
    "    for _ in range(5):\n",
    "        x = UpSampling2D()(x)\n",
    "        x = layers.Conv2DTranspose(512, (3, 3), strides=1, padding='same', use_bias=False)(x)\n",
    "        x = layers.LeakyReLU(.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(1,3,1,'same')(x)\n",
    "    x = layers.Activation('sigmoid')(x)\n",
    "\n",
    "    model = keras.Model(input,x)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_discriminator():\n",
    "\n",
    "    input = layers.Input((128,128,1))\n",
    "    x = input\n",
    "    k = 1\n",
    "    for _ in range(6):\n",
    "        x = layers.Conv2D(32*k, (4, 4), strides=(2, 2), padding='same')(x)\n",
    "        x = layers.LeakyReLU()(x)\n",
    "        k *= 2\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    x = miniBatch(100,5)(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "    output = layers.Activation('sigmoid')(x)\n",
    "\n",
    "\n",
    "    modelo = keras.Model(input,output)\n",
    "    \n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    label_mode=None,\n",
    "    color_mode='grayscale',\n",
    "    image_size=image_size,\n",
    "    shuffle=True,\n",
    "    seed = 1234,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "train_ds = train_ds.map(lambda x: (normalize(x)))\n",
    "\n",
    "for batch in train_ds:\n",
    "    for image in batch:\n",
    "        plt.imshow(image,cmap=plt.cm.gray)\n",
    "        plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = create_generator()\n",
    "dis = create_discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurate optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_opt = keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.5)\n",
    "dis_opt = keras.optimizers.Adam(learning_rate=1e-4/2, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step():\n",
    "    gen_loss,dis_loss = 0.,0.\n",
    "    gen_loss_iter,dis_loss_iter = 0.,0.\n",
    "    for batch in train_ds:\n",
    "        \n",
    "        noise = tf.random.normal((BATCH_SIZE,latent_dim_size))\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as dis_tape:\n",
    "            fake_imgs = gen(noise,training=True)\n",
    "            true_labels = dis(batch,training=True)\n",
    "            fake_labels = dis(fake_imgs,training=True)\n",
    "\n",
    "            gen_loss_iter = loss_gerador(fake_labels)\n",
    "            dis_loss_iter = loss_discriminador(true_labels,fake_labels)\n",
    "        \n",
    "        gen_gras = gen_tape.gradient(gen_loss_iter,gen.trainable_variables)\n",
    "        gen_opt.apply_gradients(zip(gen_gras,gen.trainable_variables))\n",
    "\n",
    "        dis_grads = dis_tape.gradient(dis_loss_iter,dis.trainable_variables)\n",
    "        dis_opt.apply_gradients(zip(dis_grads,dis.trainable_variables))\n",
    "\n",
    "        gen_loss += gen_loss_iter\n",
    "        dis_loss += dis_loss_iter\n",
    "        gen_loss_iter,dis_loss_iter = 0.,0.\n",
    "\n",
    "    return gen_loss/tf.cast(len(train_ds),tf.float32),dis_loss/tf.cast(len(train_ds),tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5000\n",
    "EPOCH_SAMPLE = 10\n",
    "n = 5\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "\n",
    "    # Histórico de Loss\n",
    "    loss_gen, loss_dis = train_step()\n",
    "    complete_hist['loss_gen'].append(loss_gen)\n",
    "    complete_hist['loss_dis'].append(loss_dis)\n",
    "    \n",
    "    # Iteração das épocas\n",
    "    if i % EPOCH_SAMPLE == 0:\n",
    "        gen.save_weights(f'models/weights/gen_{i}.weights.h5')\n",
    "        dis.save_weights(f'models/weights/dis_{i}.weights.h5')\n",
    "        # Print Loss\n",
    "        print(f'Ep = {i} | Loss_gen = {loss_gen:.4f}; Loss_dis = {loss_dis:.4f}')\n",
    "        # Salvar uma amostra das imagens\n",
    "        noise = tf.random.normal((n**2,latent_dim_size))\n",
    "        img_fake = gen(noise)\n",
    "        fig, ax = plt.subplots(n,n,figsize=(1,1))\n",
    "        plt.subplots_adjust(wspace=0,hspace=0)\n",
    "        ax = ax.ravel()\n",
    "        for ii in range(n**2):\n",
    "            ax[ii].imshow(img_fake[ii],cmap='gray')\n",
    "            ax[ii].set_axis_off()\n",
    "        fig.tight_layout(pad=0)\n",
    "        plt.savefig(f'../../imgs_fake/fig{i}.png',dpi=1000)\n",
    "        plt.close()\n",
    "\n",
    "    if i % 400 == 0:\n",
    "        gen.save(f'models/gen_model_{i}.keras')\n",
    "        dis.save(f'models/dis_model_{i}.keras')\n",
    "\n",
    "    plt.semilogy(np.array(complete_hist['loss_gen']),label=f'GEN = {loss_gen:.4f}',color='r')\n",
    "    plt.semilogy(np.array(complete_hist['loss_dis']),label=f'DIS = {loss_dis:.4f}',color='k')\n",
    "    plt.legend()\n",
    "    plt.grid(True,'minor')\n",
    "    plt.savefig('loss.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "print('==================== COMPLETE ====================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.save('../../models/gen_2_860.keras')\n",
    "dis.save('../../models/dis_2_860.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
